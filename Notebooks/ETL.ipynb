{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **ETL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descarga de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "pd.set_option('display.max_columns', None) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LESTURA DEL DATASET CREDITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('credits.csv',encoding='utf-8')\n",
    "print(np.shape(credit))\n",
    "credit.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.rename(columns={'id': 'id_pelicula'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LIMPIEZA DE LOS DATOS \n",
    "\n",
    "\n",
    "Este Dataframe CREDITS, aparentaba tener valores anidados en formato JSON, pero resultaron ser cadenas de texto. Por tal motivo, se procede a crear esta funcion, para iterar cada uno de los registro, eliminando espacios vacios y eliminando caracteres especiales, dejando como resutado un dataframe mas accesible a desanidar en la sigueinte funcion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_columnas(df, columnas):\n",
    "    for col in columnas:\n",
    "        # Itera sobre cada fila del DataFrame\n",
    "        for index, row in df.iterrows():\n",
    "            valor = row[col]\n",
    "            \n",
    "            if isinstance(valor, str):\n",
    "                # Separa la cadena por comas si es una cadena de texto\n",
    "                items = valor.split(',')\n",
    "                cleaned_items = []\n",
    "\n",
    "                for item in items:\n",
    "                    # Elimina todo lo que no sea palabras, números o el carácter ':'\n",
    "                    cleaned_item = re.sub(r'[^\\w\\s:]', '', item)\n",
    "                    # Corrige espacios vacíos (eliminar espacios adicionales)\n",
    "                    cleaned_item = cleaned_item.strip()\n",
    "\n",
    "                    # Añade el elemento limpio a la lista si no está vacío\n",
    "                    if cleaned_item:  \n",
    "                        cleaned_items.append(cleaned_item)\n",
    "\n",
    "                # Actualiza la columna con los elementos limpios\n",
    "                df.at[index, col] = ', '.join(cleaned_items)\n",
    "                print(f\"Fila {index}, Columna {col}, Elementos limpios: {', '.join(cleaned_items)}\")\n",
    "            else:\n",
    "                # Si el valor no es una cadena de texto, lo deja sin cambios\n",
    "                print(f\"Fila {index}, Columna {col}, Valor no procesado (tipo {type(valor).__name__}): {valor}\")\n",
    "\n",
    "    # Devuelve el DataFrame con todas las columnas, incluyendo las numéricas\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_limpiar = ['cast', 'crew']\n",
    "df2 = limpiar_columnas(credit, columnas_a_limpiar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una funcion para reorganizar el Dataframe. \n",
    "\n",
    "Esta funcion recibe un Dataframe, una variable de tipo lista, que contiene las columnas a modificar y otra variable tambien tipo lista que contiene los nombres de las columnas nuevas, extraidas del dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desanidar_ycrear_columnas(df, columnas, palabras_clave, columna_int):\n",
    "    # Diccionario para almacenar las nuevas columnas\n",
    "    columnas_nuevas = {clave: [] for clave in palabras_clave}\n",
    "    columna_int_values = []\n",
    "\n",
    "    # Iterar sobre las filas del DataFrame\n",
    "    for index, row in df.iterrows():\n",
    "        # Obtener el valor de la columna de tipo int\n",
    "        valor_int = row[columna_int] if columna_int in df.columns else None\n",
    "        \n",
    "        # Variable para almacenar las filas desanidadas en la iteración actual\n",
    "        filas_desanidadas = []\n",
    "        \n",
    "        # Iterar sobre las columnas que contienen datos anidados\n",
    "        for col in columnas:\n",
    "            # Verificar si el valor es una cadena, de lo contrario, continuar con la siguiente fila\n",
    "            if isinstance(row[col], str):\n",
    "                # Separar la cadena por comas\n",
    "                items = row[col].split(',')\n",
    "                \n",
    "                # Diccionario temporal para almacenar los valores de cada fila\n",
    "                temp_dict = {clave: None for clave in palabras_clave}\n",
    "                \n",
    "                for item in items:\n",
    "                    # Buscar coincidencias de las palabras clave seguidas del carácter ':'\n",
    "                    for clave in palabras_clave:\n",
    "                        if clave in item:\n",
    "                            # Extraer el valor que sigue al carácter ':'\n",
    "                            valor = re.search(rf'{clave}\\s*:\\s*(.*)', item)\n",
    "                            if valor:\n",
    "                                temp_dict[clave] = valor.group(1).strip()\n",
    "                \n",
    "                # Añadir los valores desanidados a la lista de filas desanidadas\n",
    "                filas_desanidadas.append(temp_dict)\n",
    "            else:\n",
    "                # Si el valor no es una cadena, agregar None a las listas correspondientes\n",
    "                for clave in palabras_clave:\n",
    "                    columnas_nuevas[clave].append(None)\n",
    "                # Agregar el valor de la columna de tipo int a la lista correspondiente\n",
    "                columna_int_values.append(valor_int)\n",
    "                \n",
    "        # Añadir las filas desanidadas a las listas de columnas nuevas y valores int\n",
    "        for fila in filas_desanidadas:\n",
    "            for clave in palabras_clave:\n",
    "                columnas_nuevas[clave].append(fila[clave])\n",
    "            columna_int_values.append(valor_int)\n",
    "\n",
    "    # Crear un nuevo DataFrame con las nuevas columnas\n",
    "    df_nuevo = pd.DataFrame(columnas_nuevas)\n",
    "    df_nuevo[columna_int] = columna_int_values\n",
    "    \n",
    "    return df_nuevo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COLUMNA 'CAST' DESANIDADA Y TRANSFORMADA EN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['cast_id', 'character','credit_id','gender','id','name','order','profile_path']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['cast']\n",
    "cast = desanidar_ycrear_columnas(df2, columnas_a_desanidar, palabras_clave,columna_int='id_pelicula')\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "cast.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cast.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CALUMNA 'CREW' DESANIDADA Y TRANSFORMADA EN DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['credit_id','department','gender','id','job','name','profile_path']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['crew']\n",
    "crew = desanidar_ycrear_columnas(credit, columnas_a_desanidar, palabras_clave,columna_int='id_pelicula')\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "crew.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LECTURA DEL DATASET MOVIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies_dataset.csv',encoding='utf-8')\n",
    "print(np.shape(movies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que 'df' es tu DataFrame\n",
    "movies['revenue'] = movies['revenue'].fillna(0)\n",
    "movies['budget'] = movies['budget'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Eliminar los valores nulos del campo 'release_date'\n",
    "movies = movies.dropna(subset=['release_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Convertir 'release_date' al formato AAAA-mm-dd y crear la columna 'release_year'\n",
    "movies['release_date'] = pd.to_datetime(movies['release_date'], format='%Y-%m-%d', errors='coerce')\n",
    "movies['release_year'] = movies['release_date'].dt.year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las columnas 'revenue' y 'budget' a numéricas, reemplazando errores con 0\n",
    "movies['revenue'] = pd.to_numeric(movies['revenue'], errors='coerce').fillna(0)\n",
    "movies['budget'] = pd.to_numeric(movies['budget'], errors='coerce').fillna(0)\n",
    "\n",
    "# Crear la columna 'return' con el cálculo de revenue / budget, asignando 0 cuando el presupuesto es 0\n",
    "movies['return'] = movies.apply(lambda row: row['revenue'] / row['budget'] if row['budget'] > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revisión final de las columnas afectadas\n",
    "movies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_valores_complejos(df):\n",
    "    columnas_complejas = {}\n",
    "    \n",
    "    for columna in df.columns:\n",
    "        tipos_detectados = set()\n",
    "        \n",
    "        for valor in df[columna]:\n",
    "            if isinstance(valor, str):\n",
    "                try:\n",
    "                    # Intentar cargar el valor como JSON\n",
    "                    json_valor = json.loads(valor)\n",
    "                    if isinstance(json_valor, dict):\n",
    "                        tipos_detectados.add('JSON (diccionario)')\n",
    "                    elif isinstance(json_valor, list):\n",
    "                        tipos_detectados.add('JSON (lista)')\n",
    "                    else:\n",
    "                        tipos_detectados.add('JSON (otro)')\n",
    "                except (ValueError, TypeError):\n",
    "                    tipos_detectados.add('String (no JSON)')\n",
    "            elif isinstance(valor, list):\n",
    "                tipos_detectados.add('Lista')\n",
    "            elif isinstance(valor, dict):\n",
    "                tipos_detectados.add('Diccionario')\n",
    "            elif isinstance(valor, (np.ndarray, pd.Series, pd.DataFrame)):\n",
    "                tipos_detectados.add(f'{type(valor).__name__}')\n",
    "            elif isinstance(valor, (set, tuple)):\n",
    "                tipos_detectados.add(f'{type(valor).__name__}')\n",
    "            elif isinstance(valor, complex):\n",
    "                tipos_detectados.add('Número complejo')\n",
    "        \n",
    "        if tipos_detectados:\n",
    "            columnas_complejas[columna] = tipos_detectados\n",
    "    \n",
    "    return columnas_complejas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_complejas = detectar_valores_complejos(movies)\n",
    "for columna, tipos in columnas_complejas.items():\n",
    "    print(f\"Columna       '{columna}'                             contiene los siguientes tipos de valores:                                             {', '.join(tipos)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectar_columnas_anidadas(df):\n",
    "    columnas_anidadas = {}\n",
    "    \n",
    "    for columna in df.columns:\n",
    "        tipo_anidado = None\n",
    "        \n",
    "        for valor in df[columna]:\n",
    "            if isinstance(valor, str):\n",
    "                try:\n",
    "                    # Intentar cargar el valor como JSON\n",
    "                    json_valor = json.loads(valor)\n",
    "                    if isinstance(json_valor, dict):\n",
    "                        tipo_anidado = 'JSON (diccionario)'\n",
    "                        break\n",
    "                    elif isinstance(json_valor, list):\n",
    "                        tipo_anidado = 'JSON (lista)'\n",
    "                        break\n",
    "                except (ValueError, TypeError):\n",
    "                    continue\n",
    "            elif isinstance(valor, list):\n",
    "                tipo_anidado = 'Lista'\n",
    "                break\n",
    "            elif isinstance(valor, dict):\n",
    "                tipo_anidado = 'Diccionario'\n",
    "                break\n",
    "            elif isinstance(valor, (np.ndarray, pd.Series, pd.DataFrame)):\n",
    "                tipo_anidado = type(valor).__name__\n",
    "                break\n",
    "            elif isinstance(valor, (set, tuple)):\n",
    "                tipo_anidado = type(valor).__name__\n",
    "                break\n",
    "        \n",
    "        if tipo_anidado:\n",
    "            columnas_anidadas[columna] = tipo_anidado\n",
    "    \n",
    "    return columnas_anidadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_anidadas = detectar_columnas_anidadas(movies)\n",
    "for columna, tipo in columnas_anidadas.items():\n",
    "    print(f\"Columna '{columna}' contiene valores anidados de tipo: {tipo}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRATAMIENTO DE COLUMNAS ANIDADAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BELONGS COLLECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs=movies['belongs_to_collection']\n",
    "collection_belongs=pd.DataFrame(collection_belongs)\n",
    "\n",
    "collection_belongs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_limpiarr = ['belongs_to_collection']\n",
    "collection_belongs = limpiar_columnas(collection_belongs, columnas_a_limpiarr)\n",
    "collection_belongs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def desanidar_y_crear_columnas(df, columnas, palabras_clave):\n",
    "    # Diccionario para almacenar las nuevas columnas\n",
    "    columnas_nuevas = {clave: [] for clave in palabras_clave}\n",
    "    \n",
    "    # Iterar sobre las columnas que contienen datos anidados\n",
    "    for col in columnas:\n",
    "        for index, row in df.iterrows():\n",
    "            # Verificar si el valor es una cadena, de lo contrario, continuar con la siguiente fila\n",
    "            if isinstance(row[col], str):\n",
    "                # Separar la cadena por comas\n",
    "                items = row[col].split(',')\n",
    "                \n",
    "                # Diccionario temporal para almacenar los valores de cada fila\n",
    "                temp_dict = {clave: None for clave in palabras_clave}\n",
    "                \n",
    "                for item in items:\n",
    "                    # Buscar coincidencias de las palabras clave seguidas del carácter ':'\n",
    "                    for clave in palabras_clave:\n",
    "                        if clave in item:\n",
    "                            # Extraer el valor que sigue al carácter ':'\n",
    "                            valor = re.search(rf'{clave}\\s*:\\s*(.*)', item)\n",
    "                            if valor:\n",
    "                                temp_dict[clave] = valor.group(1).strip()\n",
    "                \n",
    "                # Almacenar los valores en las listas correspondientes\n",
    "                for clave in palabras_clave:\n",
    "                    columnas_nuevas[clave].append(temp_dict[clave])\n",
    "            else:\n",
    "                # Si el valor no es una cadena, agregar None a las listas correspondientes\n",
    "                for clave in palabras_clave:\n",
    "                    columnas_nuevas[clave].append(None)\n",
    "\n",
    "    # Crear un nuevo DataFrame con las nuevas columnas\n",
    "    df_nuevo = pd.DataFrame(columnas_nuevas)\n",
    "    \n",
    "    return df_nuevo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['id','name', 'poster_path', 'backdrop_path']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['belongs_to_collection']\n",
    "collection_belongs= desanidar_y_crear_columnas(collection_belongs, columnas_a_desanidar, palabras_clave)\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "collection_belongs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_belongs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GENRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=movies['genres']\n",
    "genres=pd.DataFrame(genres)\n",
    "genres.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_limpiarr = ['genres']\n",
    "genres = limpiar_columnas(genres, columnas_a_limpiarr)\n",
    "genres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['id','name']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['genres']\n",
    "genres= desanidar_y_crear_columnas(genres, columnas_a_desanidar, palabras_clave)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar el nuevo DataFrame\n",
    "genres.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCTION COMPANIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_companies=movies['production_companies']\n",
    "production_companies=pd.DataFrame(production_companies)\n",
    "production_companies.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_limpiarr = ['production_companies']\n",
    "production_companies = limpiar_columnas(production_companies, columnas_a_limpiarr)\n",
    "production_companies.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['id','name']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['production_companies']\n",
    "production_companies= desanidar_y_crear_columnas(production_companies, columnas_a_desanidar, palabras_clave)\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "production_companies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_companies.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PRODUCTION COUNTRIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_countries=movies['production_countries']\n",
    "production_countries=pd.DataFrame(production_countries)\n",
    "production_countries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_limpiarr = ['production_countries']\n",
    "production_countries = limpiar_columnas(production_countries, columnas_a_limpiarr)\n",
    "production_countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['iso_3166_1','name']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['production_countries']\n",
    "production_countries= desanidar_y_crear_columnas(production_countries, columnas_a_desanidar, palabras_clave)\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "production_countries.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_countries.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " SPOKEN LANGUAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_languages=movies['spoken_languages']\n",
    "spoken_languages=pd.DataFrame(spoken_languages)\n",
    "spoken_languages.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_limpiarr = ['spoken_languages']\n",
    "spoken_languages = limpiar_columnas(spoken_languages, columnas_a_limpiarr)\n",
    "spoken_languages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palabras_clave = ['iso_639_1','name']\n",
    "\n",
    "# Supongamos que tienes un DataFrame llamado df1 con columnas a desanidar\n",
    "columnas_a_desanidar = ['spoken_languages']\n",
    "spoken_languages= desanidar_y_crear_columnas(spoken_languages, columnas_a_desanidar, palabras_clave)\n",
    "\n",
    "# Mostrar el nuevo DataFrame\n",
    "spoken_languages.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spoken_languages.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATASETS QUE CONSUMIRAN LAS FUNCIONES DE LA API**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MOVIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminacion de las columnas que no serán utilizadas: video, imdb_id, adult, original_title, poster_path y homepage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eliminar_columnas(df, columnas_a_eliminar):\n",
    "   \n",
    "    df_nuevo = df.drop(columns=columnas_a_eliminar, errors='ignore')\n",
    "    return df_nuevo\n",
    "\n",
    "\n",
    "columnas_a_eliminar = ['belongs_to_collection','genres','production_companies','production_countries','spoken_languages','video', 'imdb_id', 'adult', 'original_title', 'poster_path', 'homepage']\n",
    "movies_nuevo= eliminar_columnas(movies, columnas_a_eliminar)\n",
    "\n",
    "movies_nuevo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo.rename(columns={'id': 'id_pelicula'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dataframes(df1, df2, columns_to_add, on_column, how='left'):\n",
    "    \"\"\"\n",
    "    Une dos DataFrames y agrega solo las columnas especificadas del segundo DataFrame al primero.\n",
    "\n",
    "    Parameters:\n",
    "    - df1 (pd.DataFrame): El DataFrame principal al que se agregarán las columnas.\n",
    "    - df2 (pd.DataFrame): El DataFrame del que se tomarán las columnas a agregar.\n",
    "    - columns_to_add (list of str): Lista con los nombres de las columnas del segundo DataFrame que se desean agregar.\n",
    "    - on_column (str): El nombre de la columna sobre la cual se realizará la unión.\n",
    "    - how (str): Tipo de unión, como 'left', 'right', 'inner', o 'outer'. Por defecto es 'left'.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: DataFrame resultante con las columnas agregadas.\n",
    "    \"\"\"\n",
    "    # Asegurarse de que las columnas de unión tengan el mismo tipo de dato\n",
    "    df1[on_column] = df1[on_column].astype(str)\n",
    "    df2[on_column] = df2[on_column].astype(str)\n",
    "    \n",
    "    # Realiza la unión entre los DataFrames\n",
    "    df_merged = pd.merge(df1, df2[[on_column] + columns_to_add], on=on_column, how=how)\n",
    "    return df_merged\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCIONES QUE VAN A CONSUMIR EL DATASET MOVIES_NUEVO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def cantidad_filmaciones_mes( Mes ): Se ingresa un mes en idioma Español. Debe devolver la cantidad de películas que fueron estrenadas en el mes consultado en la totalidad del dataset.\n",
    "                    Ejemplo de retorno: X cantidad de películas fueron estrenadas en el mes de X\n",
    "\n",
    "def cantidad_filmaciones_dia( Dia ): Se ingresa un día en idioma Español. Debe devolver la cantidad de películas que fueron estrenadas en día consultado en la totalidad del dataset.\n",
    "                    Ejemplo de retorno: X cantidad de películas fueron estrenadas en los días X\n",
    "\n",
    "def score_titulo( titulo_de_la_filmación ): Se ingresa el título de una filmación esperando como respuesta el título, el año de estreno y el score.\n",
    "                    Ejemplo de retorno: La película X fue estrenada en el año X con un score/popularidad de X\n",
    "\n",
    "def votos_titulo( titulo_de_la_filmación ): Se ingresa el título de una filmación esperando como respuesta el título, la cantidad de votos y el valor promedio de las votaciones. La misma variable deberá de contar con al menos 2000 valoraciones, caso contrario, debemos contar con un mensaje avisando que no cumple esta condición y que por ende, no se devuelve ningun valor.\n",
    "                    Ejemplo de retorno: La película X fue estrenada en el año X. La misma cuenta con un total de X valoraciones, con un promedio de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar la columna 'B' sin crear un nuevo DataFrame\n",
    "movies_nuevo.drop('tagline', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "movies_nuevo.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCION QUE VA A USAR EL DATASET CREW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_director( nombre_director ): Se ingresa el nombre de un director que se encuentre dentro de un dataset debiendo devolver el éxito del mismo medido a través del retorno. Además, deberá devolver el nombre de cada película con la fecha de lanzamiento, retorno individual, costo y ganancia de la misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['title','release_date' ,'budget', 'revenue','return']\n",
    "on_column = 'id_pelicula'\n",
    "how = 'inner'\n",
    "\n",
    "directores= merge_dataframes(crew, movies_nuevo, columns_to_add, on_column, how)\n",
    "directores.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtrar_directores(df):\n",
    "    # Filtra las filas donde la columna 'jobs' es igual a 'Director'\n",
    "    df_directores = df[df['job'] == 'Director']\n",
    "    return df_directores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica la función para filtrar directores\n",
    "directores = filtrar_directores(directores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directores.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "directores.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directores.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCIO QUE CONSUMIRA EL DATASET CAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_actor( nombre_actor ): Se ingresa el nombre de un actor que se encuentre dentro de un dataset debiendo devolver el éxito del mismo medido a través del retorno. Además, la cantidad de películas que en las que ha participado y el promedio de retorno. La definición no deberá considerar directores.\n",
    "                    Ejemplo de retorno: El actor X ha participado de X cantidad de filmaciones, el mismo ha conseguido un retorno de X con un promedio de X por filmación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_add = ['title', 'return']\n",
    "on_column = 'id_pelicula'\n",
    "how = 'inner'\n",
    "\n",
    "actores= merge_dataframes(cast, movies_nuevo, columns_to_add, on_column, how)\n",
    "actores.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar filas con valores nulos\n",
    "actores.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actores.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________________________________________________________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **EDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis descriptivo\n",
    "movies_nuevo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(movies_nuevo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Cargar el dataset\n",
    "# dataset = pd.read_csv('ruta_al_archivo.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Seleccionar solo columnas de tipo int o float\n",
    "numeric_columns = movies_nuevo.select_dtypes(include=['int', 'float']).columns\n",
    "\n",
    "# Correlación entre variables\n",
    "plt.figure(figsize=(len(numeric_columns) * 2, 8))\n",
    "sns.heatmap(movies_nuevo[numeric_columns].corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Heatmap de Correlaciones')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_nuevo[numeric_columns].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de 'vote_average'\n",
    "sns.histplot(movies_nuevo['vote_average'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlación entre 'popularity' y 'vote_average'\n",
    "sns.scatterplot(x='popularity', y='vote_average', data=movies_nuevo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Detección de outliers\n",
    "def detectar_outliers(df, columnas):\n",
    "    outliers = {}\n",
    "    for columna in columnas:\n",
    "        Q1 = df[columna].quantile(0.25)\n",
    "        Q3 = df[columna].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lim_inferior = Q1 - 1.5 * IQR\n",
    "        lim_superior = Q3 + 1.5 * IQR\n",
    "        outliers[columna] = df[(df[columna] < lim_inferior) | (df[columna] > lim_superior)][columna].count()\n",
    "    return outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de columnas a analizar\n",
    "columnas = ['budget', 'revenue', 'return']\n",
    "\n",
    "# Obtener el número de outliers por columna\n",
    "outliers = detectar_outliers(movies_nuevo, columnas)\n",
    "print(\"Número de outliers por columna:\", outliers)\n",
    "\n",
    "# Generar el boxplot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=movies_nuevo[columnas])\n",
    "plt.title('Boxplot de Variables')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUARDAR CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo CSV\n",
    "#movies_nuevo.to_csv('MoviesF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo CSV\n",
    "#directores.to_csv('Directores.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame como un archivo CSV\n",
    "#actores.to_csv('Actores.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
